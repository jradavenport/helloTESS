{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from astropy.table import Table\n",
    "import astropy.io.fits as fits\n",
    "from astropy.stats import LombScargle, BoxLeastSquares\n",
    "import exoplanet as xo\n",
    "from stuff import FINDflare, EasyE\n",
    "\n",
    "matplotlib.rcParams.update({'font.size':18})\n",
    "matplotlib.rcParams.update({'font.family':'serif'})\n",
    "\n",
    "ftype = '.pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15889, 15990, 15991, 19996, 19990, 19981] 107837\n"
     ]
    }
   ],
   "source": [
    "# tess_dir = '/data/epyc/data/tess/'\n",
    "tess_dir = '/Users/james/Desktop/tess/'\n",
    "\n",
    "sectors = ['sector001', 'sector002', 'sector003', 'sector004', 'sector005', 'sector006']\n",
    "\n",
    "# just in case glob wants to re-order things, be sure grab them in Sector order\n",
    "sect1 = glob(tess_dir + sectors[0] + '/*.fits', recursive=True)\n",
    "sect2 = glob(tess_dir + sectors[1] + '/*.fits', recursive=True)\n",
    "sect3 = glob(tess_dir + sectors[2] + '/*.fits', recursive=True)\n",
    "sect4 = glob(tess_dir + sectors[3] + '/*.fits', recursive=True)\n",
    "sect5 = glob(tess_dir + sectors[4] + '/*.fits', recursive=True)\n",
    "sect6 = glob(tess_dir + sectors[5] + '/*.fits', recursive=True)\n",
    "\n",
    "files = sect1 + sect2 + sect3 + sect4 + sect5 + sect6\n",
    "# make into an array for looping later!\n",
    "s_lens = [len(sect1), len(sect2), len(sect3), len(sect4), len(sect5), len(sect6)]\n",
    "print(s_lens, len(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run Period/Flare search on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running sector001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/james/anaconda3/lib/python3.6/site-packages/astropy/table/table.py:2651: FutureWarning: elementwise == comparison failed and returning scalar instead; this will raise an error or perform elementwise comparison in the future.\n",
      "  result = self.as_array() == other\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(len(sectors)):\n",
    "    print('running ' + sectors[i])\n",
    "    \n",
    "    files_i = glob(tess_dir + sectors[i] + '/*.fits', recursive=True)\n",
    "\n",
    "    per_out = np.zeros(len(files_i)) -1 \n",
    "    per_amp = np.zeros(len(files_i)) -1 \n",
    "    per_med = np.zeros(len(files_i)) -1 \n",
    "    per_std = np.zeros(len(files_i)) -1 \n",
    "\n",
    "    ACF_1pk = np.zeros(len(files_i)) -1 \n",
    "    ACF_1dt = np.zeros(len(files_i)) -1\n",
    "    \n",
    "    blsPeriod = np.zeros(len(files_i)) -1 \n",
    "    blsAmpl = np.zeros(len(files_i)) -1 \n",
    "\n",
    "    EclFlg = np.zeros(len(files_i)) -1 \n",
    "\n",
    "    FL_id = np.array([])\n",
    "    FL_t0 = np.array([]) \n",
    "    FL_t1 = np.array([])\n",
    "    FL_f0 = np.array([])\n",
    "    FL_f1 = np.array([])\n",
    "    \n",
    "    if not os.path.isdir('figures/' + sectors[i]):\n",
    "        os.makedirs('figures/' + sectors[i])\n",
    "\n",
    "    for k in range(len(files_i)):\n",
    "        tbl = -1\n",
    "        df_tbl = -1\n",
    "        try:\n",
    "            tbl = Table.read(files_i[k], format='fits')\n",
    "            df_tbl = tbl.to_pandas()\n",
    "        except (OSError, KeyError, TypeError, ValueError):\n",
    "            print('k=' + str(k) + ' bad file: ' + files_i[k])\n",
    "\n",
    "        # this is a bit clumsy, but it made sense at the time when trying to chase down some bugs...\n",
    "        if tbl != -1:\n",
    "            # make harsh quality cuts, and chop out a known bad window of time (might add more later)\n",
    "            AOK = (tbl['QUALITY'] == 0) & ((tbl['TIME'] < 1347) | (tbl['TIME'] > 1350))\n",
    "\n",
    "            # do a running median for a basic smooth\n",
    "            smo = df_tbl['PDCSAP_FLUX'][AOK].rolling(128, center=True).median()\n",
    "            med = np.nanmedian(smo)\n",
    "\n",
    "            # make an output plot for every file\n",
    "            plt.close() # just in case anything is open...\n",
    "            plt.figure(figsize=(12,9))\n",
    "            plt.errorbar(tbl['TIME'][AOK], tbl['PDCSAP_FLUX'][AOK]/med, yerr=tbl['PDCSAP_FLUX_ERR'][AOK]/med, \n",
    "                         linestyle=None, alpha=0.25, label='PDC_FLUX')\n",
    "            plt.plot(tbl['TIME'][AOK], smo/med, label='128pt MED')\n",
    "\n",
    "            Smed = np.nanmedian(tbl['SAP_FLUX'][AOK])\n",
    "            plt.errorbar(tbl['TIME'][AOK], tbl['SAP_FLUX'][AOK]/Smed, yerr=tbl['SAP_FLUX_ERR'][AOK]/Smed, \n",
    "                         linestyle=None, alpha=0.25, label='SAP_FLUX')\n",
    "\n",
    "\n",
    "            # require at least 1000 good datapoints for analysis\n",
    "            if sum(AOK) > 1000:\n",
    "                # find OK points in the smoothed LC\n",
    "                SOK = np.isfinite(smo)\n",
    "\n",
    "                # flares\n",
    "                FL = FINDflare((df_tbl['PDCSAP_FLUX'][AOK][SOK] - smo[SOK])/med, \n",
    "                               df_tbl['PDCSAP_FLUX_ERR'][AOK][SOK]/med, \n",
    "                               N1=4, N2=2, N3=5, avg_std=False)\n",
    "\n",
    "                if np.size(FL) > 0:\n",
    "                    for j in range(len(FL[0])):\n",
    "                        FL_id = np.append(FL_id, k)\n",
    "                        FL_t0 = np.append(FL_t0, FL[0][j])\n",
    "                        FL_t1 = np.append(FL_t1, FL[1][j])\n",
    "                        FL_f0 = np.append(FL_f0, med)\n",
    "                        FL_f1 = np.append(FL_f1, np.nanmax(tbl['PDCSAP_FLUX'][AOK][SOK][(FL[0][j]):(FL[1][j]+1)]))\n",
    "\n",
    "                if np.size(FL) > 0:\n",
    "                    for j in range(len(FL[0])):\n",
    "                        plt.scatter(tbl['TIME'][AOK][SOK][(FL[0][j]):(FL[1][j]+1)], \n",
    "                                    tbl['PDCSAP_FLUX'][AOK][SOK][(FL[0][j]):(FL[1][j]+1)] / med, color='r', \n",
    "                                    label='_nolegend_')\n",
    "                    plt.scatter([],[], color='r', label='Flare?')\n",
    "\n",
    "\n",
    "\n",
    "                # Lomb Scargle\n",
    "                LS = LombScargle(df_tbl['TIME'][AOK][SOK], smo[SOK]/med, dy=df_tbl['PDCSAP_FLUX_ERR'][AOK][SOK]/med)\n",
    "                frequency, power = LS.autopower(minimum_frequency=1./40., \n",
    "                                                maximum_frequency=1./0.1, \n",
    "                                                samples_per_peak=7)\n",
    "                best_frequency = frequency[np.argmax(power)]\n",
    "\n",
    "                per_out[k] = 1./best_frequency\n",
    "                per_amp[k] = np.nanmax(power)\n",
    "                per_med[k] = np.nanmedian(power)\n",
    "                per_std[k] = np.nanstd(smo[SOK]/med)\n",
    "\n",
    "                if np.nanmax(power) > 0.2:\n",
    "                    LSmodel = LS.model(df_tbl['TIME'][AOK][SOK], best_frequency)\n",
    "                    plt.plot(df_tbl['TIME'][AOK][SOK], LSmodel, \n",
    "                             label='L-S P='+format(1./best_frequency, '6.3f')+'d, pk='+format(np.nanmax(power), '6.3f'))\n",
    "\n",
    "\n",
    "                # ACF w/ Exoplanet package\n",
    "                acf = xo.autocorr_estimator(tbl['TIME'][AOK][SOK], smo[SOK]/med, \n",
    "                                            yerr=tbl['PDCSAP_FLUX_ERR'][AOK][SOK]/med, \n",
    "                                            min_period=0.1, max_period=40, max_peaks=2)\n",
    "                if len(acf['peaks']) > 0:\n",
    "                    ACF_1dt[k] = acf['peaks'][0]['period']\n",
    "                    ACF_1pk[k] = acf['autocorr'][1][np.where((acf['autocorr'][0] == acf['peaks'][0]['period']))[0]][0]\n",
    "\n",
    "                if ACF_1dt[k] > 0:\n",
    "                    plt.plot(tbl['TIME'][AOK][SOK], \n",
    "                             np.nanstd(smo[SOK]/med) * ACF_1pk[k] * np.sin(tbl['TIME'][AOK][SOK] / ACF_1dt[k] * 2 * np.pi) + 1,\n",
    "                             label = 'ACF=' + format(ACF_1dt[k], '6.3f') + 'd, pk=' + format(ACF_1pk[k], '6.3f'), lw=2, alpha=0.7)\n",
    "\n",
    "                  \n",
    "                # here is where a simple Eclipse (EB) finder goes\n",
    "                EE = EasyE(smo[SOK]/med, df_tbl['PDCSAP_FLUX_ERR'][AOK][SOK]/med, N1=5, N2=3, N3=5)\n",
    "                if np.size(EE) > 0:\n",
    "                    for j in range(len(EE[0])):\n",
    "                        plt.scatter(tbl['TIME'][AOK][SOK][(EE[0][j]):(EE[1][j]+1)], \n",
    "                                    smo[SOK] [(EE[0][j]):(EE[1][j]+1)] / med, \n",
    "                                    color='k', marker='s', s=5, alpha=0.75, label='_nolegend_')\n",
    "                    plt.scatter([],[], color='k', marker='s', s=5, alpha=0.75, label='Ecl?')\n",
    "                    EclFlg[k] = 1\n",
    "\n",
    "\n",
    "                # add BLS\n",
    "                bls = BoxLeastSquares(df_tbl['TIME'][AOK][SOK], smo[SOK]/med, dy=df_tbl['PDCSAP_FLUX_ERR'][AOK][SOK]/med)\n",
    "                blsP = bls.autopower(0.1, method='fast', objective='snr')\n",
    "                blsPer = blsP['period'][np.argmax(blsP['power'])]\n",
    "                if ((4*np.nanstd(blsP['power']) + np.nanmedian(blsP['power']) < np.nanmax(blsP['power'])) & \n",
    "                    (np.nanmax(blsP['power']) > 50.) & \n",
    "                    (blsPer < 0.95 * np.nanmax(blsP['period']))\n",
    "                   ):\n",
    "                    blsPeriod[k] = blsPer\n",
    "                    blsAmpl[k] = np.nanmax(blsP['power'])\n",
    "                    plt.plot([],[], ' ', label='BLS='+format(blsPer, '6.3f')+'d')\n",
    "\n",
    "                    \n",
    "            plt.title(files_i[k].split('/')[-1] + ' k='+str(k), fontsize=12)\n",
    "            plt.ylabel('Flux')\n",
    "            plt.xlabel('BJD - 2457000 (days)')\n",
    "            plt.legend(fontsize=10)\n",
    "            plt.savefig('figures/' + sectors[i] + '/' + files_i[k].split('/')[-1] + '.jpeg', \n",
    "                        bbox_inches='tight', pad_inches=0.25, dpi=100)\n",
    "            plt.close()\n",
    "\n",
    "        \n",
    "\n",
    "    # write per-sector output files\n",
    "    ALL_TIC = pd.Series(files_i).str.split('-', expand=True).iloc[:,-3].astype('int')\n",
    "\n",
    "    flare_out = pd.DataFrame(data={'TIC':ALL_TIC[FL_id], 'i0':FL_t0, 'i1':FL_t1, 'med':FL_f0, 'peak':FL_f1})\n",
    "    flare_out.to_csv(sectors[i] + '_flare_out.csv')\n",
    "\n",
    "    rot_out = pd.DataFrame(data={'TIC':ALL_TIC, \n",
    "                                 'per':per_out, 'Pamp':per_amp, 'Pmed':per_med, 'StdLC':per_std, \n",
    "                                 'acf_pk':ACF_1pk, 'acf_per':ACF_1dt, \n",
    "                                 'bls_period':blsPeriod, 'bls_ampl':blsAmpl, 'ecl_flg':EclFlg})\n",
    "    rot_out.to_csv(sectors[i] + '_rot_out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k=848\n",
    "# tbl = Table.read(files_i[k], format='fits')\n",
    "# df_tbl = tbl.to_pandas()\n",
    "# # make harsh quality cuts, and chop out a known bad window of time (might add more later)\n",
    "# AOK = (tbl['QUALITY'] == 0) & ((tbl['TIME'] < 1347) | (tbl['TIME'] > 1350))\n",
    "\n",
    "# # do a running median for a basic smooth\n",
    "# smo = df_tbl['PDCSAP_FLUX'][AOK].rolling(128, center=True).median()\n",
    "# med = np.nanmedian(smo)\n",
    "# SOK = np.isfinite(smo)\n",
    "\n",
    "# FL = FINDflare((df_tbl['PDCSAP_FLUX'][AOK][SOK] - smo[SOK])/med, \n",
    "#                                df_tbl['PDCSAP_FLUX_ERR'][AOK][SOK]/med, \n",
    "#                                N1=4, N2=2, N3=5, avg_std=False)\n",
    "\n",
    "# if np.size(FL) > 0:\n",
    "#     for j in range(len(FL[0])):\n",
    "#         FL_id = np.append(FL_id, k)\n",
    "#         FL_t0 = np.append(FL_t0, FL[0][j])\n",
    "#         FL_t1 = np.append(FL_t1, FL[1][j])\n",
    "#         FL_f0 = np.append(FL_f0, med)\n",
    "#         FL_f1 = np.append(FL_f1, np.nanmax(tbl['PDCSAP_FLUX'][AOK][SOK][(FL[0][j]):(FL[1][j]+1)]))\n",
    "\n",
    "# if np.size(FL) > 0:\n",
    "#     for j in range(len(FL[0])):\n",
    "#         plt.scatter(tbl['TIME'][AOK][SOK][(FL[0][j]):(FL[1][j]+1)], \n",
    "#                     tbl['PDCSAP_FLUX'][AOK][SOK][(FL[0][j]):(FL[1][j]+1)] / med, color='r', \n",
    "#                     label='_nolegend_')\n",
    "#     plt.scatter([],[], color='r', label='Flare?')\n",
    "\n",
    "\n",
    "\n",
    "# # Lomb Scargle\n",
    "# LS = LombScargle(df_tbl['TIME'][AOK][SOK], smo[SOK]/med, dy=df_tbl['PDCSAP_FLUX_ERR'][AOK][SOK]/med)\n",
    "# frequency, power = LS.autopower(minimum_frequency=1./40., \n",
    "#                                 maximum_frequency=1./0.1, \n",
    "#                                 samples_per_peak=7)\n",
    "# best_frequency = frequency[np.argmax(power)]\n",
    "\n",
    "# per_out[k] = 1./best_frequency\n",
    "# per_amp[k] = np.nanmax(power)\n",
    "# per_med[k] = np.nanmedian(power)\n",
    "# per_std[k] = np.nanstd(smo[SOK]/med)\n",
    "\n",
    "# if np.nanmax(power) > 0.2:\n",
    "#     LSmodel = LS.model(df_tbl['TIME'][AOK][SOK], best_frequency)\n",
    "#     plt.plot(df_tbl['TIME'][AOK][SOK], LSmodel, \n",
    "#              label='L-S P='+format(1./best_frequency, '6.3f')+'d, pk='+format(np.nanmax(power), '6.3f'))\n",
    "\n",
    "\n",
    "# # ACF w/ Exoplanet package\n",
    "# acf = xo.autocorr_estimator(tbl['TIME'][AOK][SOK], smo[SOK]/med, \n",
    "#                             yerr=tbl['PDCSAP_FLUX_ERR'][AOK][SOK]/med, \n",
    "#                             min_period=0.1, max_period=40, max_peaks=2)\n",
    "# ACF_1dt[k] = acf['peaks'][0]['period']\n",
    "# ACF_1pk[k] = acf['autocorr'][1][np.where((acf['autocorr'][0] == acf['peaks'][0]['period']))[0]][0]\n",
    "\n",
    "# if ACF_1dt[k] > 0:\n",
    "#     plt.plot(tbl['TIME'][AOK][SOK], \n",
    "#              np.nanstd(smo[SOK]/med) * ACF_1pk[k] * np.sin(tbl['TIME'][AOK][SOK] / ACF_1dt[k] * 2 * np.pi) + 1,\n",
    "#              label = 'ACF=' + format(ACF_1dt[k], '6.3f') + 'd, pk=' + format(ACF_1pk[k], '6.3f'), lw=2, alpha=0.7)\n",
    "\n",
    "\n",
    "# # here is where a simple Eclipse (EB) finder goes\n",
    "# EE = EasyE(smo[SOK]/med, df_tbl['PDCSAP_FLUX_ERR'][AOK][SOK]/med, N1=5, N2=3, N3=5)\n",
    "# if np.size(EE) > 0:\n",
    "#     for j in range(len(EE[0])):\n",
    "#         plt.scatter(tbl['TIME'][AOK][SOK][(EE[0][j]):(EE[1][j]+1)], \n",
    "#                     smo[SOK] [(EE[0][j]):(EE[1][j]+1)] / med, \n",
    "#                     color='k', marker='s', s=5, alpha=0.75, label='_nolegend_')\n",
    "#     plt.scatter([],[], color='k', marker='s', s=5, alpha=0.75, label='Ecl?')\n",
    "#     EclFlg[k] = 1\n",
    "\n",
    "\n",
    "# # add BLS\n",
    "# bls = BoxLeastSquares(df_tbl['TIME'][AOK][SOK], smo[SOK]/med, dy=df_tbl['PDCSAP_FLUX_ERR'][AOK][SOK]/med)\n",
    "# blsP = bls.autopower(0.1, method='fast', objective='snr')\n",
    "# blsPer = blsP['period'][np.argmax(blsP['power'])]\n",
    "# if ((4*np.nanstd(blsP['power']) + np.nanmedian(blsP['power']) < np.nanmax(blsP['power'])) & \n",
    "#     (np.nanmax(blsP['power']) > 50.) & \n",
    "#     (blsPer < 0.95 * np.nanmax(blsP['period']))\n",
    "#    ):\n",
    "#     blsPeriod[k] = blsPer\n",
    "#     blsAmpl[k] = np.nanmax(blsP['power'])\n",
    "#     plt.plot([],[], ' ', label='BLS='+format(blsPer, '6.3f')+'d')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopthecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## need to re-work...\n",
    "analysis plots, etc. Needs to be reworked.\n",
    "\n",
    "there *should* be some per-sector output plots being made, but they can be made in post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,6))\n",
    "\n",
    "# s1 = np.where((FL_id < len(sect1)))[0]\n",
    "# s2 = np.where((FL_id > len(sect1)) & \n",
    "#               (FL_id < len(sect1) + len(sect2)))[0]\n",
    "# s3 = np.where((FL_id > len(sect1) + len(sect2)) & \n",
    "#               (FL_id < len(sect1) + len(sect2) + len(sect3)))[0]\n",
    "# s4 = np.where((FL_id > len(sect1) + len(sect2) + len(sect4)))[0]\n",
    "\n",
    "# _ = plt.hist((FL_t0[s1]+FL_t1[s1])/2., bins=150, alpha=0.5, label='sector001')\n",
    "# _ = plt.hist((FL_t0[s2]+FL_t1[s2])/2., bins=150, alpha=0.5, label='sector002')\n",
    "# _ = plt.hist((FL_t0[s3]+FL_t1[s3])/2., bins=150, alpha=0.5, label='sector003')\n",
    "# _ = plt.hist((FL_t0[s4]+FL_t1[s4])/2., bins=150, alpha=0.5, label='sector004')\n",
    "\n",
    "# plt.plot([0, max(FL_t1)], [25,25], lw=5, alpha=0.35, c='k', label='bad times')\n",
    "\n",
    "# plt.title(str(np.size(FL_t0))+' total flare candidates',fontsize=12)\n",
    "# plt.xlabel('epoch number')\n",
    "# plt.ylabel('# flare candidates')\n",
    "# plt.legend(fontsize=12)\n",
    "# plt.yscale('log')\n",
    "# plt.savefig('flare_hist.jpeg', dpi=150, bbox_inches='tight', pad_inches=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redo above, but w/ loop now\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "for i in range(len(s_lens)):\n",
    "    si = np.where((FL_id >= np.cumsum([0]+s_lens[0:i+1])[i]) & \n",
    "                  (FL_id < np.cumsum([0]+s_lens[0:i+1])[i+1]))\n",
    "    \n",
    "    _ = plt.hist((FL_t0[si]+FL_t1[si])/2., bins=150, alpha=0.5, label='sector'+str(i+1))\n",
    "\n",
    "plt.plot([0, max(FL_t1)], [25,25], lw=5, alpha=0.35, c='k', label='bad times')\n",
    "\n",
    "plt.title(str(np.size(FL_t0))+' total flare candidates',fontsize=12)\n",
    "plt.xlabel('epoch number')\n",
    "plt.ylabel('# flare candidates')\n",
    "plt.legend(fontsize=12)\n",
    "plt.yscale('log')\n",
    "plt.savefig('flare_hist.jpeg', dpi=150, bbox_inches='tight', pad_inches=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_TIC = pd.Series(files).str.split('-', expand=True).iloc[:,-3].astype('int')\n",
    "\n",
    "flare_out = pd.DataFrame(data={'TIC':ALL_TIC[FL_id], 'i0':FL_t0, 'i1':FL_t1, 'med':FL_f0, 'peak':FL_f1})\n",
    "flare_out.to_csv('flare_out_v04.csv')\n",
    "\n",
    "rot_out = pd.DataFrame(data={'TIC':ALL_TIC, \n",
    "                             'per':per_out, 'Pamp':per_amp, 'Pmed':per_med, 'StdLC':per_std, \n",
    "                             'acf_pk':ACF_1pk, 'acf_per':ACF_1dt})\n",
    "rot_out.to_csv('rot_out_v04.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW MATCH OUTPUT TO GAIA FILE, PLOT ROTATION ON THE CMD, AND PROT VS COLOR\n",
    "# could I be looping over this? Probably, yes... meh\n",
    "\n",
    "df1 = pd.read_csv(tess_dir + 'gaiatess1_xmatch_1arsec-result.csv')\n",
    "df2 = pd.read_csv(tess_dir + 'gaiatess2_xmatch_1arsec-result.csv')\n",
    "df3 = pd.read_csv(tess_dir + 'gaiatess3_xmatch_1arsec-result.csv')\n",
    "df4 = pd.read_csv(tess_dir + 'gaiatess4_xmatch_1arsec-result.csv')\n",
    "df5 = pd.read_csv(tess_dir + 'gaiatess5_xmatch_1arsec-result.csv')\n",
    "df6 = pd.read_csv(tess_dir + 'gaiatess6_xmatch_1arsec-result.csv')\n",
    "\n",
    "df = pd.concat([df1, df2, df3, df4, df5, df6], \n",
    "               ignore_index=True, sort=False)\n",
    "\n",
    "plt.figure(figsize=(9,8))\n",
    "_ = plt.hist2d(df['ra'], df['dec'], bins=(200,200), cmap=plt.cm.magma_r)\n",
    "_ = plt.hist2d(df['ra']-360, df['dec'], bins=(200,200), cmap=plt.cm.magma_r)\n",
    "plt.xlim(-180,180)\n",
    "plt.xlabel('RA [deg]')\n",
    "plt.ylabel('Dec [deg]')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdata = pd.merge(df, rot_out, right_on='TIC', left_on='ticid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gdata.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = np.where(np.isfinite(gdata[u'parallax']) & # this is basically the same as the TGAS file...\n",
    "              (gdata[u'parallax_error'] / gdata[u'parallax'] < 0.1) &\n",
    "              (gdata[u'modality_flag'] == 1) & \n",
    "              (gdata[u'result_flag'] == 1) &\n",
    "              np.isfinite(gdata[u'bp_rp']) & \n",
    "              (gdata[u'phot_bp_mean_flux_error']/gdata[u'phot_bp_mean_flux'] < 0.01) & \n",
    "              (gdata[u'phot_rp_mean_flux_error']/gdata[u'phot_rp_mean_flux'] < 0.01) & \n",
    "              (gdata[u'phot_g_mean_flux_error']/gdata[u'phot_g_mean_flux'] < 0.01) & \n",
    "              (gdata['per'] > 0.1) & \n",
    "              (gdata['Pamp']/gdata['Pmed'] > 200) & \n",
    "              (gdata['Pamp'] > 0.5))[0]\n",
    "print(ok.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.scatter(gdata['bp_rp'].values[ok], gdata['per'].values[ok], s=15, alpha=0.2, c='k')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('LS Period (days)')\n",
    "plt.xlabel('$G_{BP} - G_{RP}$ (mag)')\n",
    "plt.title('TESS Sectors 1-4', fontsize=12)\n",
    "plt.savefig('color_LSper6.jpeg', dpi=150, bbox_inches='tight', pad_inches=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.scatter(gdata['bp_rp'].values[ok], gdata['acf_per'].values[ok], s=15, alpha=0.2, c='k')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('LS Period (days)')\n",
    "plt.xlabel('$G_{BP} - G_{RP}$ (mag)')\n",
    "plt.title('TESS Sectors 1-4', fontsize=12)\n",
    "plt.savefig('color_ACFper6.jpeg', dpi=150, bbox_inches='tight', pad_inches=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(per_out, acf_1dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,7))\n",
    "# plt.scatter(gdata['bp_rp'].values[ok], gdata['per'].values[ok], s=9, alpha=0.1, c='k')\n",
    "# plt.yscale('log')\n",
    "# plt.xlim(0.3,2.3)\n",
    "# plt.ylabel('LS Period (days)')\n",
    "# plt.xlabel('$G_{BP} - G_{RP}$ (mag)')\n",
    "# plt.title('TESS Sectors 1-4', fontsize=12)\n",
    "# # plt.savefig('color_per1.jpeg', dpi=150, bbox_inches='tight', pad_inches=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "\n",
    "\n",
    "# plt.scatter(gdata['bp_rp'].values[ok], gdata['per'].values[ok], s=4, alpha=0.1, c='k')\n",
    "cb,xeb,yeb,ib = plt.hist2d(gdata['bp_rp'].values[ok], np.log10(gdata['per'].values[ok]),\n",
    "                           range=[[0,2.2],[-.7,1.3]], bins=(75,70), cmap=plt.cm.Spectral_r)\n",
    "# plt.yscale('log')\n",
    "# plt.xlim(0.3,2.3)\n",
    "plt.ylabel('LS Period (days)')\n",
    "plt.xlabel('$G_{BP} - G_{RP}$ (mag)')\n",
    "plt.title('TESS Sectors 1-4', fontsize=12)\n",
    "# plt.savefig('color_per1.jpeg', dpi=150, bbox_inches='tight', pad_inches=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcb,xeb,yeb,ib = plt.hist2d(gdata['bp_rp'], \n",
    "                           gdata['phot_g_mean_mag'] - 5. * np.log10(gdata[u'r_est'].values) + 5, \n",
    "                           range=[[-1,4],[-5,15]], bins=(75,75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "\n",
    "\n",
    "plt.contour(xcb.T, extent=[xeb.min(),xeb.max(),yeb.min(),yeb.max()], levels=[2,100], colors='k', alpha=0.25)\n",
    "\n",
    "plt.scatter(gdata['bp_rp'][ok], gdata['phot_g_mean_mag'][ok] - 5. * np.log10(gdata[u'r_est'].values[ok]) + 5, \n",
    "            alpha=0.6, s=9, c=(gdata['per'].values[ok]), cmap=plt.cm.Spectral_r)\n",
    "\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('LS Period (days)')\n",
    "\n",
    "plt.xlabel('$G_{BP} - G_{RP}$ (mag)')\n",
    "plt.ylabel('$M_G$ (mag)')\n",
    "plt.title('TESS Sectors 1-4', fontsize=12)\n",
    "plt.ylim(15,-5)\n",
    "\n",
    "# plt.savefig('cmd_per1.jpeg', dpi=150, bbox_inches='tight', pad_inches=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msbad = np.where((gdata['phot_g_mean_mag'][ok] - 5. * np.log10(gdata[u'r_est'].values[ok]) + 5 > 5) & \n",
    "                 (gdata['phot_g_mean_mag'][ok] - 5. * np.log10(gdata[u'r_est'].values[ok]) + 5 < 13) & \n",
    "                 (gdata['bp_rp'][ok] > 0.5))[0]\n",
    "print(np.shape(msbad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "\n",
    "plt.scatter(gdata['bp_rp'][ok[msbad]], gdata['phot_g_mean_mag'][ok[msbad]] - 5. * np.log10(gdata[u'r_est'].values[ok[msbad]]) + 5, \n",
    "            alpha=0.6, s=9, c=(gdata['per'].values[ok[msbad]]), cmap=plt.cm.Spectral_r)\n",
    "\n",
    "cb = plt.colorbar()\n",
    "cb.set_label('LS Period (days)')\n",
    "plt.xlabel('$G_{BP} - G_{RP}$ (mag)')\n",
    "plt.ylabel('$M_G$ (mag)')\n",
    "# plt.title('TESS Sectors 1,2', fontsize=12)\n",
    "plt.ylim(10.2,4)\n",
    "# plt.xlim(1,2)\n",
    "\n",
    "# plt.savefig('cmd_per2.jpeg', dpi=150, bbox_inches='tight', pad_inches=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, (a0, a1) = plt.subplots(ncols=1, nrows=2, sharex=True, \n",
    "                             gridspec_kw = {'height_ratios':[1,3]},\n",
    "                             figsize=(7,9))\n",
    "\n",
    "a0.scatter(gdata['bp_rp'].values[ok[msbad]], np.log10(gdata['per'].values[ok[msbad]]), s=2, alpha=0.2, c='k')\n",
    "# a0.set_yscale('log')\n",
    "a0.set_ylabel('log LS Period (days)')\n",
    "# plt.xlabel('$G_{BP} - G_{RP}$ (mag)')\n",
    "# plt.xlim(0.67,1.7)\n",
    "a0.set_ylim(0, 1.3)\n",
    "a0.set_title('TESS Sectors 1-4', fontsize=12)\n",
    "\n",
    "\n",
    "a1.scatter(gdata['bp_rp'][ok], gdata['phot_g_mean_mag'][ok] - 5. * np.log10(gdata[u'r_est'].values[ok]) + 5, \n",
    "            alpha=0.6, s=9, c=(gdata['per'].values[ok]), cmap=plt.cm.Spectral_r)\n",
    "\n",
    "# cbar = plt.colorbar()\n",
    "# cbar.set_label('LS Period (days)')\n",
    "\n",
    "a1.set_xlabel('$G_{BP} - G_{RP}$ (mag)')\n",
    "a1.set_ylabel('$M_G$ (mag)')\n",
    "a1.set_ylim(15,-5)\n",
    "\n",
    "fig.subplots_adjust(hspace=0)\n",
    "\n",
    "# plt.savefig('cmd_per1.jpeg', dpi=150, bbox_inches='tight', pad_inches=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.scatter(gdata['bp_rp'].values[ok[msbad]], gdata['per'].values[ok[msbad]], s=15, alpha=0.2, c='k')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('LS Period (days)')\n",
    "plt.xlabel('$G_{BP} - G_{RP}$ (mag)')\n",
    "plt.xlim(0.67,1.7)\n",
    "plt.ylim(1,30)\n",
    "# plt.title('TESS Sectors 1,2', fontsize=12)\n",
    "plt.savefig('color_per2_4.jpeg', dpi=150, bbox_inches='tight', pad_inches=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc1 = np.where((gdata['ra'][ok] > 0) & \n",
    "               (gdata['ra'][ok] < 2.2) & \n",
    "               (gdata['dec'][ok] > -31) & \n",
    "               (gdata['dec'][ok] < 29))[0]\n",
    "print(np.shape(bc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.scatter(gdata['bp_rp'].values[ok[bc1]], gdata['per'].values[ok[bc1]], alpha=0.5, c='k')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('LS Period (days)')\n",
    "plt.xlabel('$G_{BP} - G_{RP}$ (mag)')\n",
    "plt.title('Blanco 1', fontsize=12)\n",
    "# plt.savefig('color_per3.jpeg', dpi=150, bbox_inches='tight', pad_inches=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NBINS=200\n",
    "\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "# s1 = np.where((FL_id < len(sect1)))[0]\n",
    "# s2 = np.where((FL_id > len(sect1)) & \n",
    "#               (FL_id < len(sect1) + len(sect2)))[0]\n",
    "# s3 = np.where((FL_id > len(sect1) + len(sect2)))[0]\n",
    "\n",
    "\n",
    "n1,be1,_ = plt.hist((FL_t0[s1]+FL_t1[s1])/2.,bins=NBINS, alpha=0.5, label='sector001')\n",
    "n2,be2,_ = plt.hist((FL_t0[s2]+FL_t1[s2])/2.,bins=NBINS, alpha=0.5, label='sector002')\n",
    "n3,be3,_ = plt.hist((FL_t0[s3]+FL_t1[s3])/2.,bins=NBINS, alpha=0.5, label='sector003')\n",
    "n4,be4,_ = plt.hist((FL_t0[s4]+FL_t1[s4])/2.,bins=NBINS, alpha=0.5, label='sector004')\n",
    "\n",
    "\n",
    "\n",
    "plt.title(str(np.size(FL_t0))+' flare candidates',fontsize=12)\n",
    "plt.xlabel('epoch number')\n",
    "plt.ylabel('# stars')\n",
    "plt.legend(fontsize=12)\n",
    "plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(10**np.mean(np.log10(n1)) + 2 * 10**np.std(np.log10(n1)))\n",
    "print(10**np.mean(np.log10(n2)) + 2 * 10**np.std(np.log10(n2)))\n",
    "print(10**np.mean(np.log10(n3)) + 2 * 10**np.std(np.log10(n3)))\n",
    "print(10**np.mean(np.log10(n4)) + 2 * 10**np.std(np.log10(n4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to loopify this\n",
    "\n",
    "FLCUT = 25\n",
    "\n",
    "OK = np.empty(len(FL_id), dtype='bool') * False\n",
    "for k in range(len(n1)):\n",
    "    tt = np.where(#(FL_id[s1] < 15889) & \n",
    "                  ((FL_t0[s1]+FL_t1[s1])/2. >= be1[k]) & \n",
    "                  ((FL_t0[s1]+FL_t1[s1])/2. < be1[k+1]))[0]\n",
    "    if n1[k] < FLCUT:\n",
    "        OK[s1[tt]] = True\n",
    "\n",
    "\n",
    "for k in range(len(n2)):\n",
    "    tt = np.where(#(FL_id[s2] >= 15889) & \n",
    "                  ((FL_t0[s2]+FL_t1[s2])/2. >= be2[k]) & \n",
    "                  ((FL_t0[s2]+FL_t1[s2])/2. < be2[k+1]))[0]\n",
    "    if n2[k] < FLCUT:\n",
    "        OK[s2[tt]] = True\n",
    "\n",
    "        \n",
    "for k in range(len(n3)):\n",
    "    tt = np.where(#(FL_id[s3] >= 15889) & \n",
    "                  ((FL_t0[s3]+FL_t1[s3])/2. >= be3[k]) & \n",
    "                  ((FL_t0[s3]+FL_t1[s3])/2. < be3[k+1]))[0]\n",
    "    if n3[k] < FLCUT:\n",
    "        OK[s3[tt]] = True\n",
    "\n",
    "        \n",
    "for k in range(len(n4)):\n",
    "    tt = np.where(#(FL_id[s3] >= 15889) & \n",
    "                  ((FL_t0[s4]+FL_t1[s4])/2. >= be4[k]) & \n",
    "                  ((FL_t0[s4]+FL_t1[s4])/2. < be4[k+1]))[0]\n",
    "    if n4[k] < FLCUT:\n",
    "        OK[s4[tt]] = True\n",
    "\n",
    "\n",
    "        \n",
    "sum(OK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,7))\n",
    "# s1 = np.where((FL_id < 15889))[0]\n",
    "# s2 = np.where((FL_id >= 15889))[0]\n",
    "\n",
    "_ = plt.hist((FL_t0[s1]+FL_t1[s1])/2.,bins=NBINS, alpha=0.5, label='sector001')\n",
    "_  = plt.hist((FL_t0[s2]+FL_t1[s2])/2.,bins=NBINS, alpha=0.5, label='sector002')\n",
    "plt.plot([0, max(FL_t1)], [FLCUT, FLCUT], c='k')\n",
    "\n",
    "# plt.title(str(np.size(FL_t0))+' flare candidates',fontsize=12)\n",
    "plt.xlabel('epoch number')\n",
    "plt.ylabel('# stars')\n",
    "plt.legend(fontsize=12)\n",
    "plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flare_out2 = pd.DataFrame(data={'TIC':ALL_TIC[FL_id], 'i0':FL_t0, 'i1':FL_t1, \n",
    "                                'med':FL_f0, 'peak':FL_f1, 'FLOK':OK})\n",
    "fdata = pd.merge(flare_out2, df, left_on='TIC', right_on='ticid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fok = np.where(np.isfinite(fdata[u'parallax']) & # this is basically the same as the TGAS file...\n",
    "               (fdata[u'parallax_error'] < 0.1) &\n",
    "               (fdata[u'modality_flag'] == 1) & \n",
    "               (fdata[u'result_flag'] == 1) &\n",
    "               np.isfinite(fdata[u'bp_rp']) & \n",
    "               (fdata[u'phot_bp_mean_flux_error']/fdata[u'phot_bp_mean_flux'] < 0.01) & \n",
    "               (fdata[u'phot_rp_mean_flux_error']/fdata[u'phot_rp_mean_flux'] < 0.01) & \n",
    "               (fdata[u'phot_g_mean_flux_error']/fdata[u'phot_g_mean_flux'] < 0.01) & \n",
    "               (fdata['FLOK'] == True) & \n",
    "               (fdata['peak']/fdata['med'] > 0.02))[0]\n",
    "print(Fok.shape)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "\n",
    "plt.scatter(fdata['bp_rp'][Fok], fdata['phot_g_mean_mag'][Fok] - 5. * np.log10(fdata[u'r_est'].values[Fok]) + 5, \n",
    "            alpha=0.6, s=9)\n",
    "\n",
    "# cb = plt.colorbar()\n",
    "# cb.set_label('LS Period (days)')\n",
    "plt.xlabel('$G_{BP} - G_{RP}$ (mag)')\n",
    "plt.ylabel('$M_G$ (mag)')\n",
    "# plt.title('TESS Sectors 1,2', fontsize=12)\n",
    "plt.ylim(15,-5)\n",
    "# plt.savefig('cmd_per2.jpeg', dpi=150, bbox_inches='tight', pad_inches=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
